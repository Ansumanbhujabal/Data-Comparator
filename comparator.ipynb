{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf4a7c08-0cc4-4bbf-add0-c8e1086da4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (2.1.4)\n",
      "Requirement already satisfied: sentence-transformers in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (3.2.1)\n",
      "Requirement already satisfied: scikit-learn in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sentence-transformers) (4.46.0)\n",
      "Requirement already satisfied: tqdm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sentence-transformers) (2.2.1+cu121)\n",
      "Requirement already satisfied: scipy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sentence-transformers) (0.26.1)\n",
      "Requirement already satisfied: Pillow in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.2)\n",
      "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.6.68)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas sentence-transformers scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d807700d-eb1a-498e-86a8-f0a30ebdb28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ba7b0af-5141-470c-a3f2-f215f7553341",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv(\"companyName.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb6da3f4-dfd2-4c63-aa41-3420bc0efbbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CompanyName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allcargo Logistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blue Dart Express</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gati Ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transport Corporation of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VRL Logistics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      CompanyName\n",
       "0              Allcargo Logistics\n",
       "1               Blue Dart Express\n",
       "2                        Gati Ltd\n",
       "3  Transport Corporation of India\n",
       "4                   VRL Logistics"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32cbfa6e-6d67-46b9-bb8b-2c242cd6cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.read_csv(\"merged_output_Personality_jan9.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4c1fcbc-3455-4460-9a30-dd7555dc368a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Search Query</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ratan Tata</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dhirubhai Ambani</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fouaad Mirza</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G. V. Ramanjaneyulu</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dinesh K Sarraf</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Search Query                                          Image URL\n",
       "0           Ratan Tata   https://encrypted-tbn0.gstatic.com/images?q=tb...\n",
       "1     Dhirubhai Ambani   https://encrypted-tbn0.gstatic.com/images?q=tb...\n",
       "2         Fouaad Mirza   https://encrypted-tbn0.gstatic.com/images?q=tb...\n",
       "3  G. V. Ramanjaneyulu   https://encrypted-tbn0.gstatic.com/images?q=tb...\n",
       "4      Dinesh K Sarraf   https://encrypted-tbn0.gstatic.com/images?q=tb..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62242005-eb77-4cab-95be-f18ee3c72e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=pd.read_csv(\"merged_output_logo_jan9.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d0bbd2f-6315-4f61-9e00-7ad33270ce37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Search Query</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SIFS India</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hindustan Unilever Limited</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Okaya Power Group</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hindustan Zinc Limited</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Veolia India</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Search Query  \\\n",
       "0                   SIFS India    \n",
       "1   Hindustan Unilever Limited    \n",
       "2          Okaya Power Group      \n",
       "3     Hindustan Zinc Limited      \n",
       "4              Veolia India       \n",
       "\n",
       "                                           Image URL  \n",
       "0  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...  \n",
       "1  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...  \n",
       "2  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...  \n",
       "3  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...  \n",
       "4  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e486c6f-7df2-4a1f-80a1-8dab040b71a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "small_list_df = pd.read_csv(\"companyName.csv\", header=None, names=[\"CompanyName\"])\n",
    "large_list_df = pd.read_csv(\"merged_output_logo_jan9.csv\", header=None, names=[\"Search Query\"])\n",
    "small_careers = small_list_df[\"CompanyName\"].tolist()\n",
    "large_careers = large_list_df[\"Search Query\"].tolist()\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Encode the career names into vectors\n",
    "small_embeddings = model.encode(small_careers, convert_to_tensor=True)\n",
    "large_embeddings = model.encode(large_careers, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9918b094-a7ea-4a83-8486-bde55c22ddcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching complete!\n",
      "Exact matches saved to 'exact_matches_with_images.csv'\n",
      "Semantic matches saved to 'semantic_matches_with_images.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Load the data\n",
    "df1 = pd.read_csv(\"companyName.csv\", header=None, names=[\"CompanyName\"])\n",
    "df3 = pd.read_csv(\"merged_output_logo_jan9.csv\", header=None, names=[\"Search Query\", \"Image URL\"])\n",
    "\n",
    "# Convert columns to lists\n",
    "small_careers = df1[\"CompanyName\"].tolist()\n",
    "large_careers = df3[\"Search Query\"].tolist()\n",
    "image_urls = df3[\"Image URL\"].tolist()\n",
    "\n",
    "# Initialize lists for results\n",
    "exact_matches = []\n",
    "semantic_matches = []\n",
    "\n",
    "# Find exact matches first\n",
    "for small_career in small_careers:\n",
    "    exact_match = [\n",
    "        (large_career, image_urls[idx]) \n",
    "        for idx, large_career in enumerate(large_careers) \n",
    "        if large_career.lower() == small_career.lower()\n",
    "    ]\n",
    "    if exact_match:\n",
    "        exact_matches.append([small_career, exact_match[0][0], exact_match[0][1]])\n",
    "\n",
    "# Save the exact matches to a DataFrame\n",
    "exact_matches_df = pd.DataFrame(exact_matches, columns=[\"CompanyName\", \"Matched Search Query\", \"Image URL\"])\n",
    "exact_matches_df.to_csv(\"new_exact_matches_with_images.csv\", index=False)\n",
    "\n",
    "# Load the pre-trained Sentence-BERT model for semantic matching\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Encode the career names into vectors\n",
    "small_embeddings = model.encode(small_careers, convert_to_tensor=True)\n",
    "large_embeddings = model.encode(large_careers, convert_to_tensor=True)\n",
    "\n",
    "# For semantic matches\n",
    "for i, small_career in enumerate(small_careers):\n",
    "    # Skip if it's already in the exact matches\n",
    "    if any(small_career.lower() == exact_match[0].lower() for exact_match in exact_matches):\n",
    "        continue\n",
    "    \n",
    "    # Compute cosine similarity between this career and all careers in the large list\n",
    "    similarities = util.pytorch_cos_sim(small_embeddings[i], large_embeddings)\n",
    "    \n",
    "    # Get the index of the best match\n",
    "    best_match_idx = similarities.argmax().item()\n",
    "    \n",
    "    # Get the corresponding Search Query and Image URL\n",
    "    best_match_query = large_careers[best_match_idx]\n",
    "    best_match_image_url = image_urls[best_match_idx]\n",
    "    \n",
    "    # Append the result to semantic matches\n",
    "    semantic_matches.append([small_career, best_match_query, best_match_image_url])\n",
    "\n",
    "# Convert the semantic matches to a DataFrame\n",
    "semantic_matches_df = pd.DataFrame(semantic_matches, columns=[\"CompanyName\", \"Matched Search Query\", \"Image URL\"])\n",
    "semantic_matches_df.to_csv(\"new_matches_with_images.csv\", index=False)\n",
    "\n",
    "print(\"Matching complete!\")\n",
    "print(\"Exact matches saved to 'exact_matches_with_images.csv'\")\n",
    "print(\"Semantic matches saved to 'semantic_matches_with_images.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c2a1e4-15b2-475e-85c3-8f3b12953aff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8080f7d-436d-4e38-97e6-3765345b1225",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5=pd.read_csv(\"new_matches_with_images.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69ae63c6-6a92-4588-88b9-559f3aab17fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>Matched Search Query</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CompanyName</td>\n",
       "      <td>The Craft Company</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allcargo Logistics</td>\n",
       "      <td>Allcargo Logistics</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Blue Dart Express</td>\n",
       "      <td>Blue Dart Express</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gati Ltd</td>\n",
       "      <td>Gati Ltd</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Transport Corporation of India</td>\n",
       "      <td>Transport Corporation of India</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      CompanyName               Matched Search Query  \\\n",
       "0                     CompanyName               The Craft Company      \n",
       "1              Allcargo Logistics                Allcargo Logistics    \n",
       "2               Blue Dart Express                Blue Dart Express     \n",
       "3                        Gati Ltd                         Gati Ltd     \n",
       "4  Transport Corporation of India   Transport Corporation of India     \n",
       "\n",
       "                                           Image URL  \n",
       "0  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...  \n",
       "1  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...  \n",
       "2  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...  \n",
       "3  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...  \n",
       "4  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d174fe24-1dc5-401e-8d79-e616b1185dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef154ed9-5290-4835-b0d6-d2e80f383c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered matches saved to 'exact_normalized_matches.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the data\n",
    "df5 = pd.read_csv(\"new_matches_with_images.csv\")\n",
    "\n",
    "# Function to normalize strings by removing spaces, commas, dots, special signs, and making it lowercase\n",
    "def normalize_string(s):\n",
    "    return re.sub(r'[^a-z0-9]', '', s.lower())\n",
    "\n",
    "# Filter rows where normalized CompanyName matches normalized Matched Search Query\n",
    "filtered_df = df5[\n",
    "    df5.apply(lambda row: normalize_string(row[\"CompanyName\"]) == normalize_string(row[\"Matched Search Query\"]), axis=1)\n",
    "]\n",
    "\n",
    "# Save the filtered DataFrame to a new CSV\n",
    "filtered_df.to_csv(\"new_v1_exact_normalized_matches.csv\", index=False)\n",
    "\n",
    "print(\"Filtered matches saved to 'exact_normalized_matches.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be9647a-e386-4446-ae95-49583ea18f54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3aeae0-f871-4c78-b2f8-ca73d9c45ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88be72c-224b-40c6-9edc-647a2dfb58bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b95f42-6391-494b-b7ba-d9e1a09f720e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "# For each career in the small list, find the most semantically similar careers in the large list\n",
    "for i, small_career in enumerate(small_careers):\n",
    "    # Compute cosine similarity between this career and all careers in the large list\n",
    "    similarities = util.pytorch_cos_sim(small_embeddings[i], large_embeddings)\n",
    "    \n",
    "    # Get the indices of top matches, let's say top 5 matches\n",
    "    top_matches = np.argpartition(similarities[0], -1)[-1:]\n",
    "    # top_match_idx = similarities[0].argmax().item()  # Get the index of the most similar career\n",
    "    # top_match = large_careers[top_match_idx]\n",
    "\n",
    "    \n",
    "    # Get the corresponding career names from large list\n",
    "    matched_careers = [large_careers[idx] for idx in top_matches]\n",
    "    \n",
    "    # Save the career and matched careers to the results list\n",
    "    results.append([small_career, \", \".join(matched_careers)])\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "output_df = pd.DataFrame(results, columns=[\"Career (Small List)\", \"Matched Careers (Large List)\",\"Image URL\"])\n",
    "\n",
    "# Save the result to a CSV file\n",
    "output_df.to_csv(\"matched_careers_top1.csv\", index=False)\n",
    "\n",
    "print(\"Matching complete! Results saved to matched_careers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224e9ed4-caa6-4b6c-8cce-7aa9cdd478a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_matches = []\n",
    "semantic_matches = []\n",
    "\n",
    "# Find exact matches first\n",
    "for small_career in small_careers:\n",
    "    exact_match = [large_career for large_career in large_careers if large_career.lower() == small_career.lower()]\n",
    "    if exact_match:\n",
    "        exact_matches.append([small_career, \", \".join(exact_match)])\n",
    "\n",
    "# Save the exact matches to a CSV file\n",
    "exact_matches_df = pd.DataFrame(exact_matches, columns=[\"Career (Small List)\", \"Exact Matched Careers\"])\n",
    "exact_matches_df.to_csv(\"exact_matches_2.csv\", index=False)\n",
    "\n",
    "# Load the pre-trained Sentence-BERT model for semantic matching\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Encode the career names into vectors\n",
    "small_embeddings = model.encode(small_careers, convert_to_tensor=True)\n",
    "large_embeddings = model.encode(large_careers, convert_to_tensor=True)\n",
    "\n",
    "# For each career in the small list, find the most semantically similar careers in the large list\n",
    "for i, small_career in enumerate(small_careers):\n",
    "    # Skip if it's already in the exact matches\n",
    "    if any(small_career.lower() == exact_career[0].lower() for exact_career in exact_matches):\n",
    "        continue\n",
    "    \n",
    "    # Compute cosine similarity between this career and all careers in the large list\n",
    "    similarities = util.pytorch_cos_sim(small_embeddings[i], large_embeddings)\n",
    "    \n",
    "    # Get the indices of top matches, let's say top 5 matches\n",
    "    top_matches = np.argpartition(similarities[0], -5)[-5:]\n",
    "    \n",
    "    # Get the corresponding career names from large list\n",
    "    matched_careers = [large_careers[idx] for idx in top_matches]\n",
    "    \n",
    "    # Save the career and matched careers to the semantic matches list\n",
    "    semantic_matches.append([small_career, \", \".join(matched_careers)])\n",
    "\n",
    "# Convert the semantic matches to a DataFrame\n",
    "semantic_matches_df = pd.DataFrame(semantic_matches, columns=[\"Career (Small List)\", \"Semantically Matched Careers\"])\n",
    "\n",
    "# Save the semantic matches result to a CSV file\n",
    "semantic_matches_df.to_csv(\"semantic_matches_2.csv\", index=False)\n",
    "\n",
    "print(\"Matching complete! Exact matches saved to 'exact_matches.csv' and semantic matches saved to 'semantic_matches.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
